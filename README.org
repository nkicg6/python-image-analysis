#+TITLE: Python functions for figures and analysis
#+DATE: 2017-09-07
#+OPTIONS: toc:nil author:nil title:nil date:nil num:nil ^:{} \n:1 todo:nil
#+PROPERTY: header-args :exports both :eval no-export :tangle imageanalysis.py
#+LATEX_HEADER: \usepackage[margin=1.0in]{geometry}
#+LATEX_HEADER: \hypersetup{citecolor=black,colorlinks=true,urlcolor=blue,linkbordercolor=blue,pdfborderstyle={/S/U/W 1}}
#+LATEX_HEADER: \usepackage[round]{natbib}
#+LATEX_HEADER: \renewcommand{\bibsection}

This document is a work in progress and contains useful python functions I have discovered or written to aid in image analysis of microscopy data and making figures for presentations. Most of my work is done in python or R and I use Emacs [[http://orgmode.org/][Org-mode]] for [[http://www.literateprogramming.com/knuthweb.pdf][literate programming]]. 
My goal for writing scientific papers is to work in org-mode and have all my figures generated programmatically when the document compiles to PDF. This makes the work more reproducible and easier to work with. I will be adding to this document as I work and learn. Most of it will not be org-mode specific, except where indicated. 

This document is [[http://orgmode.org/manual/Extracting-source-code.html][tangled]] into the accompanying python source doc in the repo and can be downloaded and used freely.

* As a module
I am working on integrating these into a PyPi module. I made a class to contain images and the accompanying metadata which is [[https://github.com/nkicg6/imagetools][here]]. I will keep updating this as I go/need. 

Suggestions and contributions to either project are welcome!
* Links and resources
Here is a collection of links and resources I have come across. 
- [[http://scikit-image.org/docs/dev/auto_examples/index.html][Scikit image tutorials]] are excellent. This is one of the best resources I have found.
  - Long walk through of [[http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_morphology.html#sphx-glr-auto-examples-xx-applications-plot-morphology-py][morphological filtering]] is especially useful.
- [[https://github.com/scikit-image/skimage-tutorials/blob/3f991ba579b04fdf893654d3fe725a6b736bce2a/lectures/three_dimensional_image_processing.ipynb][Excellent skimage 3D analysis]] tutorial. 
- The [[https://github.com/scikit-image/skimage-tutorials/blob/3f991ba579b04fdf893654d3fe725a6b736bce2a/lectures/three_dimensional_image_processing.ipynb][scikit-image]] github page contains some excellent tutorials you can walk though as well
- Great segmentation [[http://flothesof.github.io/removing-background-scikit-image.html][notebook]]
- [[https://zulko.github.io/blog/2014/11/13/things-you-can-do-with-python-and-pov-ray/][Moviepy]] seems cool. 
- A professor at Caltech has some excellent lecture [[http://bi1x.caltech.edu/2015/tutorials/image_processing_1.html][online]] focused on segmenting bacteria from images.
  - [[http://bi1x.caltech.edu/2015/tutorials/image_processing_2.html][Part 2]]
  - Other [[http://bi1x.caltech.edu/2015/handouts.html][modules]] from the course
  - Cool [[http://bi1x.caltech.edu/2015/tutorials/intro_to_python.html][intro to python]]
* Making figures

#+BEGIN_SRC python :session example :results silent :exports code
  # Emacs-plot venv
  import os
  import matplotlib
  matplotlib.use('Agg')
  import matplotlib.pyplot as plt
  if not 'img' in os.listdir("."):
      os.mkdir('img')
      #+END_SRC 


** Basics

The first step is to read images. For this, we use a python wrapper around the [[https://www.openmicroscopy.org/bio-formats/][OME Bioformats]] command line tool [[https://docs.openmicroscopy.org/bio-formats/5.7.0/users/comlinetools/index.html][bfconvert]]. I wrote a python wrapper around bfconvert that will convert images or directories and store them in a dedicated folder for easier use and organization. This script and the documentation is [[https://github.com/nkicg6/tif-convert][available on github]]. 

Next, images are read in using skimage like so 

#+BEGIN_SRC python :results output


  # using scikit-image to read images

  import skimage.io
  from skimage import img_as_float

  def read_img(path, asfloat=False):
      img = skimage.io.imread(path)
      if not asfloat:
          return img
      img = img_as_float(img)
      return img

#+END_SRC

** Parse metadata
   
Images are converted to [[https://www.openmicroscopy.org/][OME-Tiff]] format because this is an open source data format that preserves all metadata and can be opened by virtually any image reader. The following function will uses the =tifffile= library to read the image metadata from the first page of the tiff file. 

#+NAME: Parse metadata
#+BEGIN_SRC python :results output


  # my function for parsing metadata from ome-tiffs and imagej tiffs

  import re
  import tifffile
  import xml.etree.ElementTree as ET


  def metadata(path):
      """accepts the path to an ome-tif file, or imageJ tif file.
      Attempts to validates image dimensions, returns pixel size 
      and units
      following ome-tif xml schema:
      http://www.openmicroscopy.org/Schemas/OME/2016-06"""
      try:
          with tifffile.TiffFile(path) as tif:
              if tif.is_ome:
                  raw_metadata = tif[0].image_description
                  parse = ET.fromstring(raw_metadata)
                  pixels = parse.find('.//{http://www.openmicroscopy.org/Schemas/OME/2016-06}Pixels')
                  # ensure all pixel units are the same
                  assert pixels.get('PhysicalSizeXUnit') == pixels.get('PhysicalSizeZUnit') == \
                  pixels.get('PhysicalSizeYUnit')
                  units = pixels.get('PhysicalSizeXUnit')
                  assert pixels.get('PhysicalSizeY') == pixels.get('PhysicalSizeX')
                  # save pixel size
                  size = pixels.get('PhysicalSizeY')
                  # Z can be easily implemented (pizels.get(PhysicalSizeZ))
                  return float(size), units
              else:
                  # hopefully it is imagej format
                  raw_metadata = tif[0]
                  # ensure xy pixels are the same size
                  assert raw_metadata.x_resolution == raw_metadata.y_resolution
                  # imageJ encodes as 'pixels per micron' so we should convert back
                  size = 1/(raw_metadata.y_resolution[0]/raw_metadata.y_resolution[-1])
                  check_units = raw_metadata.image_description.decode('utf-8')
                  # regex to search for units. 
                  regex_check = re.search('(?<=unit=)\w+',check_units)
                  if regex_check.group(0) == 'micron':
                      # If micron, return Unicode micron
                      units = '\xb5m'
                      return float(size), units
                  else:
                      return 'Could not determine pixel size. expected micron \
                      got >> {}'.format(regex_check.group(0))
      except AssertionError:
          print("Image dimensions or units do not match")
      except ValueError as e:
          print("Incompatible format >>> {}".format(e))
      except Exception as x:
          print("Error. >>> {}".format(x))

#+END_SRC

I recently updated this function to also parse ImageJ encoded tifs. When you save a tif from imageJ, it encodes only the essential info in the file. By parsing the tif as explained in the [[https://pypi.python.org/pypi/tifffile/0.4][documentation]] like so:

#+BEGIN_SRC python :results output


  # example of metadata returned form an imageJ tif

  import tifffile  
  neun_path_example = '/Volumes/EXTENSION/RESTREPOLAB/images/neuronavigation/macklin_zeiss/2017-08-01/figures/MAX_2017-08-01_H001-017_img006.tif'
  with tifffile.TiffFile(neun_path_example) as tif:
      images = tif.asarray()
      for page in tif:
          for tag in page.tags.values():
              t = tag.name, tag.value
              print(t)

#+END_SRC

#+RESULTS:
#+begin_example
('new_subfile_type', 0)
('image_width', 2048)
('image_length', 2048)
('bits_per_sample', 16)
('photometric', 1)
('image_description', b'ImageJ=1.51n\nimages=2\nchannels=2\nmode=grayscale\nunit=micron\nspacing=5.0\nloop=false\nmin=348.0\nmax=2437.0\n')
('strip_offsets', (367,))
('samples_per_pixel', 1)
('rows_per_strip', 2048)
('strip_byte_counts', (16777216,))
('x_resolution', (769230, 1000000))
('y_resolution', (769230, 1000000))
('resolution_unit', 1)
('imagej_byte_counts', (12, 32))
('imagej_metadata', b'IJIJrang\x00\x00\x00\x01@u\xc0\x00\x00\x00\x00\x00@\xa3\n\x00\x00\x00\x00\x00@o \x00\x00\x00\x00\x00@\xa2r\x00\x00\x00\x00\x00')
#+end_example

You see a different set of results. So in ome-tif files, all the metadata is a xml blob in the =image_description= tag, while in a ImageJ encoded tif, you have to extract it from a series of top level tags. It turns out that these tags exist in the ome-tif ones too, but I think the xml is better to stick with if it is available. Also, it is important to note how ImageJ encodes resolution. It seems to encode a float as a tuple (divide tuple[0] by tuple[-1] for the float) and furthermore this number is =units/pixel=. very weird. I take the inverse to fix it. The imageJ parsing is less robust and informative, but it works. I think =spacing= in =image_description= refers to z-step size but I am not sure. Anyways this seems to work for parsing two tif encoding formats. 

** add scalebar

use the [[https://pypi.python.org/pypi/matplotlib-scalebar][matplotlib-scalebar]] class. Here are some common arguments I like.

#+NAME: scalebar class
#+BEGIN_SRC python :results output
  # example of a scalebar

  import matplotlib.pyplot as plt
  from matplotlib_scalebar.scalebar import ScaleBar

  scalebar = ScaleBar(pixelLength, units, location = 'lower right', 
                     fixed_value = 25, color = 'black', frameon = False)
#+END_SRC

Here is a function to use it in a figure. 

#+NAME: Image with scalebar
#+BEGIN_SRC python :results output


  # function for plotting an image with a scalebar

  import matplotlib.pyplot as plt
  from matplotlib_scalebar.scalebar import ScaleBar

  def scale_plot(img, imageSize, scale, units, scalebar_length, color):
      plt.figure(figsize=imageSize)
      plt.imshow(img)
      plt.axis('off')
      scalebar = ScaleBar(scale, units, location = 'lower right', 
                          fixed_value = scalebar_length, color = color, frameon = False)
      plt.gca().add_artist(scalebar)
#+END_SRC

** panel figures
#+NAME: Simple three panel figure
#+BEGIN_SRC python :session example :results output
  ## example data
  from matplotlib_scalebar.scalebar import ScaleBar
  import numpy as np # for image example

  np.random.seed(0)
  example_image = np.random.rand(250,250,3)

  fig = plt.figure(figsize=(10,10))
  fig.suptitle('Experiment title here', fontsize=15)
  one = fig.add_subplot(131)
  plt.imshow(example_image[:,:,0])
  one.set_title('Time one', fontsize=15)
  plt.axis('off')
  two = fig.add_subplot(132)
  two.set_title('Time two', fontsize=15)
  plt.imshow(example_image[:,:,1], cmap='gray')
  plt.axis('off')
  three = fig.add_subplot(133)
  plt.imshow(example_image[:,:,2])
  three.set_title('Time three', fontsize=15)
  scalebar = ScaleBar(1,'um',location='lower right', fixed_value=25, color='black',frameon=True)
  plt.gca().add_artist(scalebar)
  plt.axis('off')
  #plt.tight_layout()
  plt.subplots_adjust(wspace=0.01)
  plt.subplots_adjust(top=1.35)
  plt.savefig('img/three_panel.png',bbox_inches='tight')
#+END_SRC


Gives the following figure

#+ATTR_HTML: :width 50% :height 50%
#+ATTR_LATEX: :placement [H]
[[file:img/three_panel.png]]

*** cooler

#+NAME: Three panel with linescans underneath
#+BEGIN_SRC python :session example :results silent
  import skimage.measure
  # make line profiles

  np.random.seed(0)
  example_image = np.random.rand(250,250,3)

  start_coords = [50,50]
  stop_coords = [150,150]

  # make line profiles


  start_y_line = skimage.measure.profile_line(example_image[:,:,0], start_coords, stop_coords)
  middle_y_line = skimage.measure.profile_line(example_image[:,:,1], start_coords, stop_coords)
  last_y_line = skimage.measure.profile_line(example_image[:,:,2], start_coords, stop_coords)
  linescan_dist = (np.linalg.norm(np.array(start_coords) - np.array(stop_coords)))
  line_axis = np.linspace(0,linescan_dist+1,len(start_y_line))

  # column 1
  fig = plt.figure(figsize=(10,8))
  fig.suptitle('1040nm exposure', fontsize=15)
  one = fig.add_subplot(231)
  plt.imshow(example_image[:,:,0], cmap='gray')
  plt.plot([start_coords[0],stop_coords[0]], [start_coords[1],stop_coords[1]],'r-', linewidth=4)
  one.set_title('Start exposure', fontsize=15)
  plt.axis('off')
  onescan = fig.add_subplot(234)
  plt.plot(line_axis, start_y_line,'-', color='black')
  onescan.spines['right'].set_visible(False)
  onescan.spines['top'].set_visible(False)
  plt.ylabel('Fluorescence intensity (AU)', fontsize=15)
  plt.xlabel(r'Distance ($\mu{}m$)', fontsize=15)


  #column2
  two = fig.add_subplot(232)
  two.set_title('22 s', fontsize=15)
  plt.imshow(example_image[:,:,1], cmap='gray')
  plt.plot([start_coords[0],stop_coords[0]], [start_coords[1],stop_coords[1]],'r-', linewidth=4)
  plt.axis('off')
  middlescan = fig.add_subplot(235)
  plt.plot(line_axis, middle_y_line,'-', color='black')
  plt.axis('off')


  #column3
  three = fig.add_subplot(233)
  plt.imshow(example_image[:,:,2], cmap='gray')
  plt.plot([start_coords[0],stop_coords[0]], [start_coords[1],stop_coords[1]],'r-', linewidth=4)
  three.set_title('45 s', fontsize=15)
  plt.axis('off')
  scalebar = ScaleBar(1,'um',location='lower right', fixed_value=25,color = 'black', frameon=True)
  plt.gca().add_artist(scalebar)
  lastscan = fig.add_subplot(236)
  plt.plot(line_axis, last_y_line, '-', color='black')
  plt.axis('off')
  plt.subplots_adjust(wspace=0.01)
  plt.subplots_adjust(top=.9)
  fig.savefig('img/three_panel_with_scans.png', bbox_inches='tight')
#+END_SRC


That code generates the figure below


#+ATTR_LATEX: :placement [H]
[[file:img/three_panel_with_scans.png]]

*** In a row

#+NAME: Three panel in a row
#+BEGIN_SRC python :session example :results silent

  np.random.seed(0)
  example_image = np.random.rand(250,250,3)

  roi_stim_coords_start = [50,50]
  roi_stim_coords_end = [150,150]

  # make line profiles


  pre_exposure_y_line = skimage.measure.profile_line(example_image[:,:,0], start_coords, stop_coords)
  post_exposure_y_line = skimage.measure.profile_line(example_image[:,:,1], start_coords, stop_coords)
  linescan_dist = (np.linalg.norm(np.array(roi_stim_coords_start) - np.array(roi_stim_coords_end)))
  stim_line_axis = np.linspace(0,linescan_dist+1,len(pre_exposure_y_line))

  # TP 1
  fig = plt.figure(figsize=(25,10))
  one = fig.add_subplot(141)
  plt.imshow(example_image[:,:,0], cmap='gray')
  one.set_title('Pre-exposure',fontsize=20)
  plt.plot([roi_stim_coords_start[0],roi_stim_coords_end[0]], 
           [roi_stim_coords_start[1],roi_stim_coords_end[1]], 'r', linewidth=4)
  plt.axis('off')

  # TP 2
  two = fig.add_subplot(142)
  two.set_title('During exposure',fontsize=20)
  plt.imshow(example_image[:,:,1], cmap='gray')
  plt.plot([roi_stim_coords_start[0],roi_stim_coords_end[0]], 
          [roi_stim_coords_start[1],roi_stim_coords_end[1]], 'r', linewidth=4)
  plt.axis('off')

  # TP 3 
  three = fig.add_subplot(143)
  plt.imshow(example_image[:,:,2], cmap='gray')
  three.set_title('post-exposure',fontsize=20)
  plt.axis('off')
  scalebar = ScaleBar(1,'um',location='lower left', fixed_value=25,color = 'black', frameon=True)
  plt.gca().add_artist(scalebar)
  plt.plot([roi_stim_coords_start[0],roi_stim_coords_end[0]], 
           [roi_stim_coords_start[1],roi_stim_coords_end[1]], 'r', linewidth=4)

  # linescans
  four = fig.add_subplot(144)
  plt.plot(stim_line_axis, pre_exposure_y_line, '--', color='blue',linewidth=2, label='pre-exposure')
  plt.plot(stim_line_axis, post_exposure_y_line, '-', color='black',linewidth=2, label='post-exposure')
  four.spines['right'].set_visible(False)
  four.spines['top'].set_visible(False)
  four.legend(loc='lower center', fontsize=15)
  plt.ylabel('Fluorescence intensity (a.u.)',fontsize=15)
  plt.xlabel(r'Distance ($\mu{}m$)',fontsize=15)
  plt.subplots_adjust(wspace=None)
  fig.savefig('img/in_a_row.png', bbox_inches='tight')
#+END_SRC

How about in a row?


#+ATTR_LATEX: :placement [H]
[[file:img/in_a_row.png]]

** Subplots

The following format works well for splitting two channels and merging. Some of my microscopy images are only two channels. To plot these, I add an extra channel of zeros. To do this, do the following:

#+BEGIN_SRC python :results output


  # create three channel image from 2 channel


  import numpy as np

  two_channel_image = np.random.rand(250,250,2)
  print('Original image shape is {}'.format(two_channel_image.shape))

  # make it three

  now_three =np.dstack((two_channel_image[:,:,0], two_channel_image[:,:,1],
                     np.zeros_like(two_channel_image[:,:,0])))
  print('Three channel image shape is {}'.format(now_three.shape))

#+END_SRC 

#+RESULTS:
: Original image shape is (250, 250, 2)
: Three channel image shape is (250, 250, 3)




#+BEGIN_SRC python :session example :results silent :exports both

  two_channel_image = np.random.rand(250,250,2)
  now_three =np.dstack((two_channel_image[:,:,0], two_channel_image[:,:,1], 
                        np.zeros_like(two_channel_image[:,:,0])))

  # plot 2 channels of an image with scalebar
  fig = plt.figure(figsize=(10,10))
  one = fig.add_subplot(131)
  plt.imshow(now_three[:,:,0], cmap="Greens_r") # note colormap
  one.axis('off')
  one.set_title('Channel 1',size=15)
  two = fig.add_subplot(132)
  plt.imshow(now_three[:,:,1] ,cmap="Reds_r") # note colormap
  two.set_title('Channel 2',size=15)
  two.axis('off')
  scalebar = ScaleBar(1, units, location = 'lower right', 
                          fixed_value = 25, color = 'black', frameon = True)
  three = fig.add_subplot(133)
  plt.imshow(now_three)
  plt.gca().add_artist(scalebar)
  three.set_title('Merge', size=15)
  three.axis('off')
  plt.tight_layout()
  fig.savefig('img/fake_channels.png', bbox_inches='tight')

#+END_SRC


Easy way to work with channels. 



#+ATTR_LATEX: :placement [H]
[[file:img/fake_channels.png]]


more to come...

* Processing
** Max projections
Shocked there was not already a method for this?


#+BEGIN_SRC python  :results output
## max project

import numpy as np


def max_project(image, start_slice = 0, stop_slice = None):
    """ takes ONE CHANNEL nd array image
        optional args = start_slice, stop_slice
        range to max project into
        returns new projection"""
    if stop is None:
        stop = 0
    print(stop)
    max_proj = [image[i,:,:] for i in range(start,image.shape[stop])]
    return np.maximum.reduce(max_proj)
#+END_SRC

I will expand this for multichannel images and also implement mean projection, sum projection etc. 
Example coming soon. 
* Analysis

Interactive line profiles are cool!

#+NAME: Interactive line profiles
#+BEGIN_SRC python :results output


  # draw a line profile interactively


  import matplotlib
  matplotlib.use('TKAgg') # I don't have matplotlib installed as a framework so I need this..
  from skimage import data
  from skimage.viewer import ImageViewer
  from skimage.viewer.plugins.lineprofile import LineProfile

  def make_profile(image):
      """ 
      Takes a 2D image, gives an PyQt image
      viewer that you can make a ROI on. 
      returns line profile values
      """
      viewer = ImageViewer(image)
      viewer += LineProfile()
      _, line = zip(*viewer.show())
      return line

#+END_SRC

Dray your profile line then close the image. This returns a list of length 1 containing a tuple. The tuple contains the image array and the line profile. Very annoying, but I used argument unpacking with zip(*args) to fix it. I used the tutorial and put them in a function. 

How similar are your images? You can use structured similarity index (SSIM) to get an indication. 

#+BEGIN_SRC python :results output

  # compare image channels with SSIM

  import skimage.measure

  score, diff = skimage.measure.compare_ssim(image[0,:,:], image[1,:,:], full=True,
                                             gaussian_weights=True, sigma=1.5, 
                                             use_sample_covariance=False)
#+END_SRC

a score of 1 is most similar and a score of -1 is least similar. See the [[http://scikit-image.org/docs/0.13.x/api/skimage.measure.html#skimage.measure.compare_ssim][skimage documentation]] and the [[https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf][paper]]. 

